---
title: database
categories: db
tags: [db]
---
# X
## sql执行顺序
FROM → ON → JOIN → WHERE → GROUP BY → HAVING → SELECT →DISTINCT → ORDER BY → LIMIT

## 从库会不会丢数据？
MySQL的高可用基本都依赖于binlog。主从复制的两种模式：
* 异步复制：默认。主服务器将数据修改操作记录到binlog中，并将日志传输给从服务器。从服务器接收到二进制日志后，会异步地应用这些日志进行数据复制。
  * 优点：及时响应，主服务器不会受到从服务器的影响而等待确认，可以提高主服务器的性能。
  * 缺点：可能存在数据传输延迟，且从服务器上的复制过程是不可靠的。如果主服务器故障，尚未应用到从服务器的数据可能会丢失。
* 半同步复制：主服务器将数据修改操作记录到binlog，并等待至少一个从服务器确认已接收到并应用了这些日志后才继续执行后续操作。
  * 优点：可以提供更高的数据一致性和可靠性，确保至少一个从服务器与主服务器保持同步。如果主服务器故障，已经确认接收并应用到从服务器的数据不会丢失。
  * 缺点：由于需要等待从服务器的确认，因此相对于异步复制，会增加一定的延迟，可能会影响主服务器的性能。
* 全同步复制：所有从服务器都确认。

## 删除数据的方式
执行速度: drop > truncate >> DELETE
* drop: DDL定义语言，同Truncate。执行后立即生效，立刻释放磁盘空间，无法找回。将删除表的结构被依赖的约束(constrain)、触发器(trigger)、索引(index)，依赖于该表的存储过程/函数将保留,但是变为invalid状态；
* truncate: DDL定义语言，快速清空一个表，并且重置auto_increment的值。执行后立即生效，立刻释放磁盘空间，无法找回；truncate table类似于drop table 然后creat table，只不过这个create table 的过程做了优化，比如表结构文件之前已经有了；
* DELETE: DML操作语言，只删除数据，会走事务，执行时会触发trigger。在 InnoDB 中，DELETE不会把数据删除，只是给删除的数据打个已删除标记，因此表文件在磁盘上所占空间不会变小，存储空间不会被释放，只是把删除的数据行设置为不可见。虽然未释放磁盘空间，但是下次插入数据的时候，仍然可以重用这部分空间。操作是一行一行执行的，同时将该行的删除操作记录在redo和undo表空间中以便进行回滚（rollback）和重做操作，生成的大量日志也会占用磁盘空间。可以用```optimize table name```来释放DELETE的磁盘空间: 效果是重建表，更新索引统计信息，释放未使用的索引空间。操作会锁表，所以最好不要在高峰期使用。


# 索引
## B+树索引
**B+树的优点**，也就是它更适合作索引数据结构的原因：
* 磁盘读写代价更低：B+树的内部节点没有指向关键字具体信息的指针，其内部节点相对B树更小，如果把所有同一内部节点的关键字存放在同一盘块中，那么盘块所能容纳的关键字数量也越多，一次性读入内存的需要查找的关键字也就越多，相对IO读写次数就降低了。
* 查询效率更加稳定：由于非终结点并不是最终指向文件内容的结点，而只是叶子结点中关键字的索引。所以任何关键字的查找必须走一条从根结点到叶子结点的路。所有关键字查询的路径长度相同，每一个数据的查询效率相当。
* 由于数据都存储在叶子结点中，分支结点均为索引，方便扫库，只需要扫一遍叶子结点即可，但是B树因为其分支结点同样存储着数据，我们要找到具体的数据，需要进行一次中序遍历按序来扫，所以B+树更加适合在区间查询的情况。

**B树的缺点**，对应地：
B树在提高了磁盘IO性能的同时并没有解决元素遍历的效率低下的问题。数据库中基于范围的查询是非常频繁的，而B树对于此类操作效率太低，因为它在节点中存储索引和数据，从而在”减少磁盘IO“这一关键优化上依然存在很大空间。B+索引也就是B树基础上，把数据域转移到叶子节点，所有非叶子节点只保存索引。

## 建索引建议
* 最左前缀匹配原则，mysql会一直向右匹配直到遇到范围查询(>、<、between、like)就停止匹配，比如a = 1 and b = 2 and c > 3 and d = 4 如果建立(a,b,c,d)顺序的索引，d是用不到索引的，如果建立(a,b,d,c)的索引则都可以用到，a,b,d的顺序可以任意调整；
* =和in可以乱序，比如a = 1 and b = 2 and c = 3 建立(a,b,c)索引可以任意顺序，mysql的查询优化器会帮你优化成索引可以识别的形式；
* 尽量选择区分度高的列作为索引，区分度的公式是count(distinct col)/count(*)，表示字段不重复的比例，比例越大我们扫描的记录数越少，唯一键的区分度是1，而一些状态、性别字段可能在大数据面前区分度就是0；
* 索引列不参与计算，保持列“干净”，比如```from_unixtime(create_time) = '2014-05-29'```就不能使用到索引，原因很简单，b+树中存的都是数据表中的字段值，但进行检索时，需要把所有元素都应用函数才能比较，显然成本太大。所以语句应该写成```create_time = unix_timestamp('2014-05-29')```；
* 扩展索引，尽量不要新建索引。比如表中已经有a的索引，现在要加(a,b)的索引，那么只需要修改原来的索引即可。

### 联合索引/符合复合索引/多列索引
当创建(a,b,c)联合索引时，相当于创建了(a)单列索引，(a,b)联合索引以及(a,b,c)联合索引。

### 索引覆盖
查询字段从非主键索引中就能获取，而不需要回表查询主键索引中的记录。

### 索引下推
[Index Condition Pushdown，简称ICP](https://www.cnblogs.com/three-fighter/p/15246577.html)
下推其实就是指将部分上层(服务层)负责的事情，交给了下层(引擎层)去处理。从而减少回表次数，即减少IO操作。

没有使用ICP的情况下，查询过程：
1. 存储引擎读取索引记录；
2. 根据索引中的主键值，定位并读取完整的行记录；
3. 存储引擎把记录交给`Server`层去检测该记录是否满足`WHERE`条件。

使用ICP的情况下，查询过程：
1. 存储引擎读取索引记录(不是完整的行记录)；
2. 判断`WHERE`条件部分能否用索引中的列来做检查，条件不满足，则处理下一行索引记录；
3. 条件满足，使用索引中的主键去定位并读取完整的行记录(就是所谓的回表)；
4. 存储引擎把记录交给`Server`层，`Server`层检测该记录是否满足`WHERE`条件其余部分。


## 聚集索引
每张表只能拥有一个聚集索引。查询优化器倾向于采用聚集索引，因为能够在叶子节点上直接找到数据，对于主键的排序查找和范围查找速度都非常快。聚集索引的存储并不是物理上连续的(维护成本将非常高)，而是逻辑上连续的。

## 辅助索引
也称非聚簇索引，叶子节点并不包含行记录的全部数据，除了包含键值以外，每个叶子节点的索引行中还包含了一个书签，用来告诉InnoDB存储引擎哪里可以找到与索引相对应的行数据。辅助索引的存在并不影响数据在聚集索引中的组织，因此每张表上可以有多个辅助索引。当通过辅助索引来查找数据时，InnoDB存储引擎会遍历辅助索引并通过叶级别的指针获得指向主键索引的主键，然后通过主键索引来找到一个完整的行记录。
*例：如果在一棵高度为3的辅助索引树中查找数据，那么需要对这棵辅助索引树遍历3次找到指定主键，如果聚集索引树的高度同样为3，那么还需要对聚集索引树进行3次查找，最终找到一个完整的行数据所在的页，因此共需要6次逻辑IO访问以得到最终的一个数据页。*


## 其他索引 
### Hash索引
基于哈希表实现，只有精确匹配索引所有列的查询才有效。对于每一行数据，存储引擎都会对所有的索引列计算一个哈希码(Hash Code)，哈希码是一个比较小的值，并且不同键值的行计算出来的哈希码是不同的。哈希索引将所有的哈希码存储在索引中，同时在哈希表中保存指向每个数据行的指针。
MySQL中，只有 Memory 引擎显式支持哈希索引，也是 Memory 引擎表默认索引类型，并且支持非唯一哈希索引。如果多个列的哈希值相同，索引会以链表的方式存放多个记录指针到同一个哈希条目中，所以哈希索引适合于精确查找；InnoDB 引擎支持的哈希索引是自适应的，会根据表的使用情况自动为表生成哈希索引，不能人为干预是否在一张表中生成哈希索引。

### 位图索引
建立B+树索引的条件：高选择性的列(后续内容)。对于低选择性的列(这里应该描述成：只有固定几个值可选的列)如性别、婚否等，位图索引可能是个好的选择。
**适用场景**
* 只有几个固定值的列；
* 不会频繁更新；
[位图索引原理](https://www.cnblogs.com/LBSer/p/3322630.html)



# 事务
事务(Transaction)是数据库区别于文件系统的重要特性之一。事务会把数据库从一种一致状态转变为另一种一致状态：提交工作时，确保所有修改要么都被保存，要么都不保存。

## 隔离级别 ACID
读未提交 
读提交 -> 脏读
可重复读 -> 不可重复读
序列化 -> 幻读

* 原子性(Atomicity)：指数据库的事务是不可分割的工作单位，即事务中任何一个SQL语句执行失败，已经成功的部分也必须撤销，数据库会退到执行事务之前的状态；
* 一致性(Consistency)：指事务将数据库从一种一致状态转变为下一种一致状态，在事务开始前和结束后，数据库的完整性约束没有被破坏，如列值的唯一性等；
* 隔离性(Isolation)：也称并发控制(Concurrency Control)、可串行化(Serializability)、锁(Locking)等。要求每个读写事务的对象对其它事务的操作对象之间能够相互分离，即该事务提交前对其它事务都不可见，通常使用锁来实现。当前数据库系统都提供了一种粒度锁(Granular Lock)的策略，允许事务仅锁住一个实体对象的子集，以此来提高事务的并发度；
* 持久性(Durability)：事务一旦提交，其结果就是永久性的，即使发生宕机等故障，数据库也能将数据恢复。持久性保证事务系统的高可靠性(High Reliability)，但不能保证高可用性(High Availability)：_从事务本身的角度保证结果的永久性，但无法避免数据库本身的故障，如RAID卡损坏、自然灾害等_；

在实现上，数据库会创建一个视图，访问的时候以视图的逻辑结果为准。在“可重复读”隔离级别下，这个视图是在事务启动时创建的，整个事务存在期间都用这个视图；在“读提交”隔离级别下，这个视图是在每个SQL语句开始执行时创建的。需要注意的是，“读未提交”隔离级别下直接返回记录上的最新值，没有视图概念；而“串行化”隔离级别下直接用加锁的方式来避免并行访问。

## 幻读
同一个查询在不同的时间产生不同的结果集，事务中就会出现所谓的幻象问题，注意，这里结果集的不同指有数据行的insert，而非update。

**快照读**
MVCC 多版本并发控制，可以解决快照读幻读问题：事务开始后(执行 begin 语句后)，执行第一个查询语句后，会创建一个视图，后续的查询语句利用这个视图，配合 undolog 版本链找到事务开始时的数据，所以事务过程中每次查询的数据都是一样的，即使中途有其他事务插入了新纪录，对当前事务也是不可见的，也就避免了幻读问题。

**当前读**
MySQL 除了普通查询是快照读，其他都是当前读，比如 update、insert、delete、select...for update，这些语句执行前都会查询最新版本的数据，然后再做进一步操作。
当前读通过间隙锁(next-key lock)解决幻读问题。

可重复读隔离级别下很大程度上避免了幻读——“读”操作的幻读问题，但没有能完全解决幻读——update操作的幻读问题。
**case1**
[更新即将被其他事务插入的行](https://xiaolincoding.com/mysql/transaction/phantom.html#第一个发生幻读现象的场景)
**case2**
[先快照读，再当前读，期间插入的数据第二次读可见。](https://xiaolincoding.com/mysql/transaction/phantom.html#第二个发生幻读现象的场景)

要避免这类特殊场景下发生的幻读现象，要尽量在开启事务之后，马上执行 select...for update 这类当前读语句，因为它会对记录加 next-key lock，从而避免其他事务插入新记录。

## log
事务的原子性、一致性、持久性通过数据库的 redo log 和 undo log 完成。redo log 称为重做日志，用来保证事务的原子性、持久性，undo log 用来保证事务的一致性。隔离性由锁来实现。
undo 不是 redo 的逆过程。redo 和 undo 都可以看作是一种恢复操作，redo 恢复提交事务修改的页操作，undo 回滚行记录到某个特定版本：两者记录的内容不同，并且 redo 通常是物理日志，记录的是页的物理修改操作，undo 是逻辑日志，根据每行记录进行记录。

**redo log vs binlog**
* redo log是InnoDB引擎特有的；binlog是MySQL的Server层实现的，所有引擎都可以使用。
* redo log是物理日志，记录的是“在某个数据页上做了什么修改”；binlog是逻辑日志，记录的是这个语句的原始逻辑，比如“给ID=2这一行的c字段加1”。
* redo log是循环写的，空间固定会用完；binlog是可以追加写入的。“追加写”是指binlog文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。

“给ID=2这一行的c字段加1”流程：
1. 执行器先找引擎取ID=2这一行。ID是主键，引擎直接用树搜索找到这一行。如果ID=2这一行所在的数据页本来就在内存中，就直接返回给执行器；否则，需要先从磁盘读入内存，然后再返回；
2. 执行器拿到引擎给的行数据，把这个值加上1，得到新的一行数据，再调用引擎接口写入这行新数据；
3. 引擎将这行新数据更新到内存中，同时将这个更新操作记录到redo log里面，此时redo log处于prepare状态。然后告知执行器执行完成了，随时可以提交事务；
4. 执行器生成这个操作的binlog，并把binlog写入磁盘；
5. 执行器调用引擎的提交事务接口，引擎把刚刚写入的redo log改成提交(commit)状态，更新完成。

最后三步看上去有点“绕”，将redo log的写入拆成了两个步骤：prepare和commit，这就是"两阶段提交"。

### 两阶段提交
两阶段提交是为了让两份日志之间的逻辑一致。binlog日志用于归档，不具备crash-safe能力。redo log自身就具备崩溃恢复的能力。

### binlog
Server层日志
格式：
* statement，记录SQL语句原文。可以用```show binlog events in 'master.000001';```查看；
* row，记录真实操作行的主键id，及操作内容；
* mixed，上面两种格式的混合。

有些statement格式的binlog可能会导致主备不一致，所以要使用row格式，但row格式的缺点是，很占空间。mixed格式下，MySQL自己会判断这条SQL语句是否可能引起主备不一致，如果有可能，就用row格式，否则就用statement格式。即mixed格式可以利用statment格式的优点，同时避免数据不一致的风险。
现在越来越多的场景要求把MySQL的binlog格式设置成row。这么做的理由有很多，一个可以直接看出来的好处：恢复数据。

### redo log
innoDB引擎层日志，记录了事务的行为，由两部分组成：内存中的重做日志缓冲(redo log buffer)，易失的；重做日志文件(redo log file)，持久的物理保存。都是以512字节的块进行存储：重做日志块(redo log block)。
通过 Force Log at Commit 机制实现事务的持久性，即当事务提交(commit)时，必须先将该事务的所有日志写入到重做日志文件进行持久化，待事务的commit操作完成才算完成。这里的日志分为两部分：redo log 和 undo log。redo log 基本是顺序写的，在数据库运行时不需要对 redo log 的文件进行读取操作，undo log 是需要进行随机读写的。
为确保日志写入重做日志文件，重做日志缓冲写入文件系统缓存后，会进行一次fsync操作，以将缓冲写入磁盘文件，该同步操作的参数 innodb_flush_log_at_trx_commit 可以手动设置：
* 1(默认)：事务提交时必须调用一次fsync操作；
* 0：事务提交时不调用fsync，而是放到 master thread 中完成(默认每秒调用一次)；
* 2：仅写入文件系统缓存，不进行fsync操作。宕机情况下会丢失未刷新到磁盘日志文件的那部分事务。

### undo log
对事务进行回滚操作。与redo存放在重做日志文件中不同，undo存放在数据库内部的一个特殊段(segment)中，这个段称为undo段(undo segment)，位于共享表空间内。undo 是逻辑日志，只是将数据库逻辑地恢复到原来的样子，所有的修改都被逻辑地取消了：对于每个 INSERT，回滚执行一个 DELETE，相应的 DELETE、UPDATE也是同样执行一个相反的操作，将修改前的行放回去。
除了回滚操作，另一个作用是完成 MVCC：当拥护读取一行记录时，若该记录已经被其它事务占用，当前事务可以通过undo读取之前的行版本信息，以此实现非锁定读。
_uodo log 会产生 redo log，也就是 uodo log 的产生会伴随这 redo log 的产生，因为 undo log 也需要持久性的保护_。

**uodo log 格式**
InnoDB 中，undo log 分为：
insert undo log：在 INSERT 操作中产生的 undo log。因为 INSERT 操作记录只对本事务可见(隔离性的要求)，对其它事务不可见，所以可以在事务提交后直接删除；
update undo log：在 DELETE、UPDATE 操作中产生的 undo log，该 undo log 需要提供 MVCC 机制，因此不能在事务提交时就删除，提交时放入 undo log 链表，等待 purge 线程进行最后的删除。



# 锁
## 表级锁
MySQL表级锁有两种：一种是表锁，一种是元数据锁(meta data lock，MDL)。
MDL不需要显式使用，在访问一个表的时候会被自动加上。作用是保证读写的正确性。如果一个查询正在遍历一个表中的数据，而执行期间另一个线程对这个表结构做变更，删了一列，那么查询线程拿到的结果跟表结构对不上，肯定是不行的。
表锁的语法是 lock tables … read/write。
### 元数据锁

### 表锁

### 意向共享锁

### 意向排他锁


## 行级锁
MySQL的行锁是在引擎层由各个引擎自己实现的。InnoDB事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时才释放，这个就是两阶段锁协议。即，如果一个事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放。

### 行锁

### 间隙锁(Gap Lock)
间隙锁之间不互锁，目标相同，保护这个间隙，不允许插入值。

### next-key lock
间隙锁和行锁合称next-key lock，每个next-key lock是前开后闭区间。

### 共享锁

### 排他锁


## 全局锁



# 集群



# 查询
## sql执行顺序
FROM → ON → JOIN → WHERE → GROUP BY → HAVING → SELECT →DISTINCT → ORDER BY→ LIMIT

不难发现，为什么连接查询很可能导致低效(笛卡尔积：m * n)，同时也可以看出，如果想要做一些查询优化工作，那么就要从 on、where 开始着手(join 中 on 等同于 where)，对过滤条件中的字段加以优化(即挑选索引时的考虑因素)

## explain分析
**语法**：explain + SQL语句
执行explain分析语句的结果列中，有几列是与索引使用情况相关的：
1. type：join 类型，判断此次查询是全表扫描还是索引扫描等信息；
2. possible_keys：指出MySQL能使用哪个索引在该表中找到行；
3. key：显示MySQL实际决定使用的键(索引)。如果没有选择索引,键是NULL；
4. key_len：显示MySQL决定使用的键长度。如果键是NULL,则长度为NULL；
5. ref：显示使用哪个列或常数与key一起从表中选择行。

[语句执行分析](https://juejin.im/post/5babb52c6fb9a05cd676c0f7)
[Explain 使用分析](https://segmentfault.com/a/1190000008131735)
